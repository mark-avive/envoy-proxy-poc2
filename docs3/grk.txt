Thank you for providing the specific use case! Your goal is to use multiple Envoy instances to manage WebSocket connections to a dynamic set of backend pods, enforce a maximum number of WebSocket connections per pod, and report the current WebSocket connection count per pod. Let’s break this down and design a solution using Envoy’s capabilities.

Overview of the Problem and Solution
Dynamic Set of Pods: Envoy can handle dynamic backends using service discovery (e.g., DNS-based or via a control plane like Istio or Consul).
Limit Max WebSocket Connections per Pod: Envoy can enforce connection limits using circuit breakers or custom logic in filters.
Report Current WebSocket Connections per Pod: Envoy can expose per-endpoint connection statistics via its admin interface or metrics (e.g., Prometheus integration), and custom logic can be used to track WebSocket-specific counts.
Since WebSocket connections are long-lived HTTP upgrades, we’ll focus on Envoy’s HTTP and WebSocket handling capabilities. Lua can be used for custom logic, but we’ll also explore native Envoy features to achieve your goals efficiently.

Solution Components
1. Dynamic Backend Discovery for Pods
Requirement: Envoy must dynamically update its list of backend pods as they scale up/down.
Solution: Use Envoy’s service discovery mechanisms to track the dynamic set of pods.
Option 1: DNS-Based Discovery (simplest)
Configure Envoy to use STRICT_DNS or LOGICAL_DNS for cluster discovery, resolving pod IPs via a service name (e.g., Kubernetes SRV records).
Option 2: Endpoint Discovery Service (EDS) (recommended for precision)
Use a control plane (e.g., Istio, Consul, or a custom EDS server) to provide real-time endpoint updates to Envoy.
In Kubernetes, Istio or Envoy’s xDS API can automatically push pod changes via EDS.
Example Config (DNS-Based):

clusters:
- name: backend_pods
  connect_timeout: 1s
  type: STRICT_DNS
  lb_policy: ROUND_ROBIN
  load_assignment:
    cluster_name: backend_pods
    endpoints:
    - lb_endpoints:
      - endpoint:
          address:
            socket_address:
              address: backend-service.default.svc.cluster.local
              port_value: 8080

2. Limit Maximum WebSocket Connections per Pod
Requirement: Enforce a max connection limit for WebSocket connections to each backend pod.
Challenge: Envoy’s built-in circuit breakers can limit total connections per cluster or per host, but WebSocket-specific limiting requires identifying WebSocket traffic (HTTP Upgrade header) and tracking per-endpoint counts.
Solution:
Step 1: Use Circuit Breakers for Basic Limits
Envoy’s circuit_breakers can enforce a max connection limit per host (pod).
Example Config:

clusters:
- name: backend_pods
  circuit_breakers:
    thresholds:
    - priority: DEFAULT
      max_connections: 10  # Max WebSocket connections per pod


Limitation: This applies to all connections, not just WebSockets, and doesn’t differentiate based on protocol.
Step 2: Custom Logic with Lua or WASM for WebSocket-Specific Limits
Use a Lua HTTP filter to detect WebSocket requests (Upgrade: websocket header) and track/maintain per-pod connection counts.
Maintain a shared state (e.g., via an external service like Redis or a local in-memory counter if Envoy instances are coordinated) to track active WebSocket connections per pod.
Reject new connections if the limit is exceeded by returning a 503 Service Unavailable or similar response.
Lua Example (Pseudo-Code):

local connection_counts = {}  -- In-memory table (not persistent across Envoy restarts)
local MAX_CONNECTIONS_PER_POD = 10

function envoy_on_request(handle)
  local is_websocket = handle:headers():get("Upgrade") == "websocket"
  if not is_websocket then
    return
  end

  local selected_host = handle:streamInfo():upstreamHost()  -- Get target pod
  local host_key = selected_host:address()  -- Use IP:port as key

  -- Initialize or increment count
  connection_counts[host_key] = (connection_counts[host_key] or 0) + 1

  if connection_counts[host_key] > MAX_CONNECTIONS_PER_POD then
    handle:respond({[":status"] = "503"}, "Max WebSocket connections reached for this pod")
    connection_counts[host_key] = connection_counts[host_key] - 1
  end
end

function envoy_on_response(handle)
  local is_websocket = handle:headers():get("Upgrade") == "websocket"
  if is_websocket then
    local host_key = handle:streamInfo():upstreamHost():address()
    connection_counts[host_key] = (connection_counts[host_key] or 0) - 1
  end
end

Challenge with Lua: Lua’s state is per-Envoy instance and not shared across multiple Envoy instances unless synchronized via an external store (e.g., Redis via an HTTP bridge like Webdis).
Better Alternative: WASM Filter or External Service
For multiple Envoy instances, consider a WASM filter (compiled from Rust/C++) or an external rate-limiting service (e.g., a sidecar or centralized Redis) to maintain shared state across Envoy instances.
Envoy can call out to this external service via an ext_authz filter to check/enforce limits before forwarding WebSocket requests.
3. Report Current WebSocket Connections per Pod
Requirement: Track and expose the number of active WebSocket connections per pod across the Envoy cluster.
Solution:
Step 1: Use Envoy’s Built-In Metrics
Envoy exposes per-upstream (per-pod) connection statistics via its stats interface.
Enable Envoy’s Prometheus stats sink to scrape metrics like upstream_cx_active (active connections per upstream host).
Example Config for Prometheus Stats:

stats_sinks:
- name: envoy.stat_sinks.prometheus
  typed_config:
    "@type": type.googleapis.com/envoy.extensions.stat_sinks.prometheus.v3.Prometheus

Limitation: upstream_cx_active counts all connections, not just WebSockets. You’ll need custom logic to filter or tag WebSocket connections.
Step 2: Custom Tracking with Lua or WASM
Extend the Lua script (from above) to log or export WebSocket connection counts to an external system (e.g., via HTTP callouts to a metrics aggregator).
Example Lua Extension:

function envoy_on_request(handle)
  local is_websocket = handle:headers():get("Upgrade") == "websocket"
  if is_websocket then
    local host_key = handle:streamInfo():upstreamHost():address()
    connection_counts[host_key] = (connection_counts[host_key] or 0) + 1
    -- Report to external metrics service (HTTP callout)
    handle:httpCall("metrics_service", {
      [":method"] = "POST",
      [":path"] = "/report",
      [":authority"] = "metrics-service"
    }, '{"host": "' .. host_key .. '", "count": ' .. connection_counts[host_key] .. '}', 1000)
  end
end

Challenge: As before, Lua state isn’t shared across Envoy instances.
Step 3: Centralized Metrics with External Service
For a multi-Envoy setup, use a centralized metrics store (e.g., Prometheus with a custom exporter, Redis, or a database) where each Envoy instance reports its WebSocket counts.
Alternatively, use Envoy’s ext_authz or a custom WASM filter to track and report metrics to a shared service.
Recommended Architecture for Multiple Envoy Instances
Since you have multiple Envoy instances, a shared state is critical for accurate connection limiting and reporting across the cluster. Here’s the recommended setup:

Dynamic Discovery with EDS
Use a control plane (e.g., Istio or custom xDS server) to push pod endpoints to all Envoy instances dynamically.
WebSocket Connection Limiting with External Service
Deploy a lightweight sidecar or centralized service (e.g., Redis or a custom rate-limiting API) to track WebSocket connections per pod across all Envoy instances.
Use Envoy’s ext_authz HTTP filter to query this service before accepting a new WebSocket connection. If the limit is exceeded, reject the request.
Example ext_authz Config:

http_filters:
- name: envoy.filters.http.ext_authz
  typed_config:
    "@type": type.googleapis.com/envoy.extensions.filters.http.ext_authz.v3.ExtAuthz
    http_service:
      server_uri:
        uri: http://rate-limit-service:8080/check
        cluster: rate_limit_service
        timeout: 0.25s
      path_prefix: /check

Reporting with Prometheus and Custom Metrics
Each Envoy instance pushes WebSocket connection updates to a centralized metrics service (or directly to Prometheus via a custom exporter).
Use Prometheus + Grafana to visualize per-pod WebSocket connection counts across the Envoy cluster.
Summary of Key Configurations

Requirement
Solution
Dynamic set of pods
Use STRICT_DNS or EDS (via xDS/Control Plane) for endpoint discovery.
Limit WebSocket connections per pod
Use circuit breakers (basic) + ext_authz with external service (precise).
Report WebSocket connections
Use Envoy metrics (upstream_cx_active) + custom reporting via ext_authz or Lua/WASM.

Conclusion and Next Steps
Lua Feasibility: Lua can be used for prototyping per-Envoy connection tracking and reporting, but it’s not ideal for a multi-Envoy setup due to lack of shared state. Use it only if you have a single Envoy instance or can synchronize state via HTTP callouts to a shared store.
Recommended Approach: Use Envoy’s ext_authz filter with a centralized rate-limiting service (e.g., Redis or a custom API) to enforce WebSocket connection limits and report counts across multiple Envoy instances. Combine with Prometheus for metrics aggregation and visualization.
Scalability: For production, consider WASM filters or Istio (if in Kubernetes) to handle advanced traffic management and metrics natively.
If you’re deploying in Kubernetes, I can provide a more tailored Istio/Envoy setup with specific manifests. If you prefer a standalone Envoy cluster, I can refine the Lua or ext_authz configuration. Let me know your environment details or any specific constraints (e.g., max connections value, number of Envoy instances, etc.)!


I’m glad to clarify this based on your question. I believe you're asking whether the solution I provided for reporting WebSocket connection counts applies to the backend server pods (i.e., the target pods behind Envoy) or the Envoy proxy pods themselves. Let me break this down based on the context of my previous response.

Answer: Yes, the reporting solution applies to backend server pods
What I proposed for reporting: In my previous response, I explained that Envoy can report the current number of active connections (including WebSocket connections, which are tracked as upgraded HTTP/1.1 connections) per backend endpoint (i.e., per backend server pod) using the stats endpoint (/stats).
Specific metric: The metric cluster.<name>.upstream.<host_ip>.<port>.cx_active reflects the active connection count to each specific backend pod (e.g., 10.42.0.11:8080 for a pod with that IP and port).
Where this is reported: This data is available from the Envoy proxy pod’s admin interface (e.g., curl http://envoy-admin:9901/stats), but it represents the connection counts to the backend server pods, not the Envoy proxy pod itself.
Clarification: The reporting does not track connections within or to the Envoy proxy pod itself (e.g., inbound connections from clients to Envoy); it tracks the upstream connections Envoy maintains to each backend pod.
Example for Clarity
If you have an Envoy proxy pod managing traffic to three backend server pods:

Backend Pod 1: 10.42.0.11:8080 with 12 active WebSocket connections.
Backend Pod 2: 10.42.0.12:8080 with 18 active WebSocket connections.
Backend Pod 3: 10.42.0.13:8080 with 5 active WebSocket connections.
The Envoy proxy pod’s stats (accessed via its admin endpoint) will show:
cluster.backend.upstream.10_42_0_11_8080.cx_active: 12
cluster.backend.upstream.10_42_0_12_8080.cx_active: 18
cluster.backend.upstream.10_42_0_13_8080.cx_active: 5

These numbers reflect the active connections to each backend server pod, not within the Envoy proxy pod.

Summary
Yes: The reporting solution I provided focuses on tracking and reporting WebSocket connection counts per backend server pod (the target pods behind Envoy).
No: It does not report connection counts for the Envoy proxy pods themselves (e.g., how many clients are connected to Envoy).
If you meant something different by "envoy proxy pods" (e.g., connections incoming to Envoy) or have additional context, please clarify, and I’ll adjust accordingly! Let me know if you’d like a specific configuration or script to extract these stats.

